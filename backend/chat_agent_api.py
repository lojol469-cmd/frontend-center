"""
ü§ñ API CHAT AGENT MULTIMODAL AVEC FAISS
========================================

API REST pour un agent de chat intelligent capable d'analyser:
- Images (JPEG, PNG, WebP)
- PDFs (extraction de texte et images)
- Documents texte

Utilise FAISS pour la recherche vectorielle et tous les mod√®les IA disponibles.

Auteur: BelikanM
Date: 13 Novembre 2025
"""

import os
import sys
import logging
import socket
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
import base64
import io
from dotenv import load_dotenv

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import uvicorn

# Imports pour traitement
from PIL import Image
import PyPDF2
import fitz  # PyMuPDF pour extraction d'images des PDFs
import numpy as np

# Imports IA
from sentence_transformers import SentenceTransformer
import faiss

# Charger variables d'environnement
load_dotenv(Path(__file__).parent / "models" / ".env")

# Ajouter le chemin des mod√®les
sys.path.append(str(Path(__file__).parent / "models"))
from unified_agent import UnifiedAgent

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import Tavily pour recherche internet
try:
    from tavily import TavilyClient
    tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
    TAVILY_AVAILABLE = True
    logger.info("‚úÖ Tavily initialis√©")
except Exception as e:
    TAVILY_AVAILABLE = False
    tavily_client = None
    logger.warning(f"‚ö†Ô∏è Tavily non disponible: {e}")

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==========================================
# 10 PROMPTS PUISSANTS POUR KIBALI AGENT
# ==========================================

SYSTEM_PROMPT = """Tu es Kibali Enfant Agent, un assistant IA ultra-puissant cr√©√© par Nyundu Francis Arnaud. 
Tu es expert en vision par ordinateur, raisonnement avanc√©, et recherche d'informations. 
Tu r√©ponds de mani√®re concise, pr√©cise et rapide. Maximum 3-4 phrases par r√©ponse sauf si demand√© autrement."""

VISION_PROMPT = """Analyse cette image avec pr√©cision. D√©cris les objets, personnes, couleurs, actions et contexte 
de mani√®re d√©taill√©e mais concise. Si c'est une interface, explique chaque √©l√©ment visible."""

REASONING_PROMPT = """Raisonne √©tape par √©tape. D√©compose le probl√®me, analyse les options, 
et donne une r√©ponse logique et structur√©e. Sois concis mais complet."""

SEARCH_PROMPT = """Recherche des informations pr√©cises et r√©centes sur ce sujet. 
Utilise Tavily pour trouver des sources fiables. R√©sume les points cl√©s en 3-5 phrases maximum."""

EXPLAIN_APP_PROMPT = """Tu es un guide expert de l'application CENTER. 
L'application CENTER est une plateforme de gestion d'employ√©s avec:
- üë§ Gestion des profils employ√©s (photos, informations)
- ü§ñ Chat intelligent avec Kibali Agent (IA multimodale)
- üì∏ Reconnaissance faciale pour pointage
- üìä Tableau de bord et statistiques
- üîê Authentification s√©curis√©e

Explique clairement et simplement comment utiliser les fonctionnalit√©s. 
Donne des instructions √©tape par √©tape si n√©cessaire."""

TECHNICAL_PROMPT = """Tu es un expert technique. Explique les concepts de mani√®re claire 
avec des exemples concrets. Adapte ton niveau selon l'utilisateur."""

CREATIVE_PROMPT = """G√©n√®re du contenu cr√©atif et original. Sois innovant dans tes propositions 
tout en restant pertinent et utile."""

PROBLEM_SOLVING_PROMPT = """Analyse le probl√®me, identifie les causes possibles, 
et propose des solutions concr√®tes et applicables imm√©diatement."""

SUMMARIZATION_PROMPT = """R√©sume l'information en gardant uniquement les points essentiels. 
Sois ultra-concis : maximum 3-4 phrases pour tout r√©sum√©."""

CONVERSATION_PROMPT = """Maintiens une conversation naturelle et engageante. 
Pose des questions de clarification si n√©cessaire. Sois amical mais professionnel."""

# Param√®tres de performance optimis√©s
MAX_TOKENS_FAST = 150  # R√©ponses rapides
MAX_TOKENS_NORMAL = 300  # R√©ponses standard
TEMPERATURE_PRECISE = 0.3  # Pr√©cis et factuel
TEMPERATURE_BALANCED = 0.7  # √âquilibr√©

# ==========================================
# D√âTECTION AUTOMATIQUE DE L'IP
# ==========================================

def get_local_ip():
    """D√©tecte l'IP locale du r√©seau"""
    try:
        # Cr√©er une socket pour obtenir l'IP locale
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        local_ip = s.getsockname()[0]
        s.close()
        return local_ip
    except Exception:
        return "127.0.0.1"

app = FastAPI(title="Chat Agent API", version="1.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# MOD√àLES PYDANTIC
# ==========================================

class ChatMessage(BaseModel):
    role: str  # 'user' ou 'assistant'
    content: str
    images: Optional[List[str]] = None  # URLs ou base64
    timestamp: Optional[str] = None

class ChatRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    use_vision: bool = True
    use_memory: bool = True
    temperature: float = 0.7

class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    sources: Optional[List[Dict[str, Any]]] = None
    reasoning: Optional[str] = None
    timestamp: str

# ==========================================
# GESTIONNAIRE DE M√âMOIRE VECTORIELLE FAISS
# ==========================================

class FAISSMemoryManager:
    """Gestionnaire de m√©moire avec FAISS pour recherche vectorielle"""
    
    def __init__(self, embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        try:
            # Essayer de charger le mod√®le depuis le cache local
            self.embedding_model = SentenceTransformer(embedding_model, local_files_only=True)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de charger le mod√®le d'embeddings: {e}")
            logger.info("‚ÑπÔ∏è Fonctionnement sans recherche vectorielle FAISS")
            self.embedding_model = None
        
        self.dimension = 384  # Dimension des embeddings MiniLM
        
        # Index FAISS (IndexFlatL2 pour recherche exacte)
        self.index = faiss.IndexFlatL2(self.dimension) if self.embedding_model else None
        
        # Stockage des m√©tadonn√©es
        self.documents: List[Dict[str, Any]] = []
        self.document_embeddings: List[np.ndarray] = []
        
        # Conversations
        self.conversations: Dict[str, List[ChatMessage]] = {}
        
        if self.embedding_model:
            logger.info(f"‚úÖ FAISS Memory Manager initialis√© (dim={self.dimension})")
        else:
            logger.info("‚úÖ Memory Manager initialis√© (mode simple sans FAISS)")
    
    def add_document(
        self,
        text: str,
        metadata: Dict[str, Any],
        doc_type: str = "text"
    ) -> int:
        """Ajouter un document √† la m√©moire vectorielle"""
        
        if not self.embedding_model:
            # Mode simple : juste stocker sans embeddings
            doc_id = len(self.documents)
            self.documents.append({
                "id": doc_id,
                "text": text,
                "type": doc_type,
                "metadata": metadata,
                "timestamp": datetime.now().isoformat()
            })
            return doc_id
        
        # Mode FAISS : avec embeddings
        # G√©n√©rer l'embedding
        embedding = self.embedding_model.encode([text])[0]
        
        # Ajouter √† FAISS
        self.index.add(np.array([embedding], dtype=np.float32))
        
        # Stocker les m√©tadonn√©es
        doc_id = len(self.documents)
        self.documents.append({
            "id": doc_id,
            "text": text,
            "type": doc_type,
            "metadata": metadata,
            "timestamp": datetime.now().isoformat()
        })
        self.document_embeddings.append(embedding)
        
        logger.info(f"üìÑ Document ajout√©: {doc_type} (ID: {doc_id})")
        return doc_id
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Rechercher les documents les plus similaires"""
        
        if not self.embedding_model:
            # Mode simple : retourner les derniers documents
            return self.documents[-k:] if self.documents else []
        
        if self.index.ntotal == 0:
            return []
        
        # G√©n√©rer l'embedding de la requ√™te
        query_embedding = self.embedding_model.encode([query])[0]
        
        # Recherche dans FAISS
        distances, indices = self.index.search(
            np.array([query_embedding], dtype=np.float32),
            min(k, self.index.ntotal)
        )
        
        # R√©cup√©rer les documents
        results = []
        for i, idx in enumerate(indices[0]):
            if idx != -1:
                doc = self.documents[idx].copy()
                doc["similarity"] = float(1 / (1 + distances[0][i]))  # Convertir distance en similarit√©
                results.append(doc)
        
        logger.info(f"üîç Recherche: {len(results)} r√©sultats pour '{query[:50]}...'")
        return results
    
    def add_to_conversation(self, conv_id: str, message: ChatMessage):
        """Ajouter un message √† une conversation"""
        if conv_id not in self.conversations:
            self.conversations[conv_id] = []
        self.conversations[conv_id].append(message)
    
    def get_conversation(self, conv_id: str) -> List[ChatMessage]:
        """R√©cup√©rer une conversation"""
        return self.conversations.get(conv_id, [])
    
    def save_to_disk(self, path: str):
        """Sauvegarder l'index FAISS sur disque"""
        faiss.write_index(self.index, f"{path}/faiss.index")
        
        with open(f"{path}/documents.json", "w", encoding="utf-8") as f:
            json.dump(self.documents, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ Index FAISS sauvegard√©: {path}")
    
    def load_from_disk(self, path: str):
        """Charger l'index FAISS depuis le disque"""
        index_path = f"{path}/faiss.index"
        docs_path = f"{path}/documents.json"
        
        if os.path.exists(index_path):
            self.index = faiss.read_index(index_path)
            logger.info(f"üìÇ Index FAISS charg√©: {self.index.ntotal} vecteurs")
        
        if os.path.exists(docs_path):
            with open(docs_path, "r", encoding="utf-8") as f:
                self.documents = json.load(f)
            logger.info(f"üìÇ {len(self.documents)} documents charg√©s")

# ==========================================
# GESTIONNAIRE DE CHAT
# ==========================================

class ChatAgentManager:
    """Gestionnaire principal du chat agent"""
    
    def __init__(self):
        # D√©sactiver temporairement les mod√®les lourds pour permettre le d√©marrage rapide
        self.agent = UnifiedAgent(
            enable_voice=False,
            enable_vision=False,
            enable_detection=False,
            enable_llm=False
        )
        self.memory = FAISSMemoryManager()
        
        # Cr√©er le dossier de stockage
        self.storage_path = Path(__file__).parent / "storage" / "chat_memory"
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # Charger la m√©moire existante
        self.memory.load_from_disk(str(self.storage_path))
        
        logger.info("‚úÖ Chat Agent Manager initialis√©")
    
    def detect_intent(self, message: str) -> str:
        """D√©tecter l'intention de l'utilisateur"""
        message_lower = message.lower()
        
        # Recherche sur internet
        if any(word in message_lower for word in ["recherche", "cherche", "trouve", "internet", "google", "web"]):
            return "search"
        
        # Explication de l'application
        if any(word in message_lower for word in ["comment", "utiliser", "fonctionner", "faire", "aide", "option", "fonction", "menu"]):
            if any(word in message_lower for word in ["application", "app", "center", "plateforme", "syst√®me"]):
                return "explain_app"
        
        # Probl√®me technique
        if any(word in message_lower for word in ["erreur", "bug", "probl√®me", "marche pas", "fonctionne pas"]):
            return "problem_solving"
        
        # R√©sum√©
        if any(word in message_lower for word in ["r√©sume", "r√©sumer", "synth√®se", "bref", "court"]):
            return "summarization"
        
        # Cr√©atif
        if any(word in message_lower for word in ["imagine", "cr√©e", "g√©n√®re", "invente", "id√©e"]):
            return "creative"
        
        # Par d√©faut : conversation normale
        return "conversation"
    
    def get_prompt_by_intent(self, intent: str) -> str:
        """Obtenir le prompt appropri√© selon l'intention"""
        prompts = {
            "search": SEARCH_PROMPT,
            "explain_app": EXPLAIN_APP_PROMPT,
            "problem_solving": PROBLEM_SOLVING_PROMPT,
            "summarization": SUMMARIZATION_PROMPT,
            "creative": CREATIVE_PROMPT,
            "reasoning": REASONING_PROMPT,
            "technical": TECHNICAL_PROMPT,
            "conversation": CONVERSATION_PROMPT
        }
        return prompts.get(intent, CONVERSATION_PROMPT)
    
    async def process_upload(
        self,
        file: UploadFile,
        description: Optional[str] = None
    ) -> Dict[str, Any]:
        """Traiter un fichier upload√© (image ou PDF) - Supporte TOUS les formats"""
        
        file_content = await file.read()
        file_type = file.content_type
        filename = file.filename
        
        results = {"filename": filename, "type": file_type, "documents": []}
        
        try:
            # === D√âTECTION UNIVERSELLE DU TYPE DE FICHIER ===
            original_type = file_type
            
            # Liste compl√®te des extensions d'images support√©es
            image_extensions = [
                'jpg', 'jpeg', 'jpe', 'jfif',  # JPEG
                'png', 'apng',                  # PNG
                'gif',                          # GIF
                'bmp', 'dib',                   # Bitmap
                'webp',                         # WebP
                'tiff', 'tif',                  # TIFF
                'svg', 'svgz',                  # SVG
                'ico', 'cur',                   # Icon
                'heic', 'heif',                 # HEIC
                'avif',                         # AVIF
                'psd',                          # Photoshop
                'raw', 'cr2', 'nef', 'arw'     # RAW formats
            ]
            
            # 1. D√âTECTION PAR EXTENSION
            if filename:
                ext = filename.lower().split('.')[-1].replace('-', '').replace('_', '')
                # Extraire l'extension m√™me si le nom contient des tirets ou underscores
                parts = filename.lower().split('.')
                if len(parts) > 1:
                    ext = parts[-1]
                    # G√©rer les cas comme "profile-1762679949026-478326994.jpg"
                    if ext in image_extensions:
                        file_type = f"image/{ext.replace('jpeg', 'jpg')}"
                        logger.info(f"üìé Extension d√©tect√©e: .{ext} ‚Üí {file_type}")
                    elif ext == 'pdf':
                        file_type = "application/pdf"
                        logger.info(f"üìé Extension PDF d√©tect√©e")
            
            # 2. D√âTECTION PAR CONTENU (si type g√©n√©rique ou inconnu)
            if file_type in ["application/octet-stream", None, ""] or not file_type.startswith("image/"):
                try:
                    # Essayer d'ouvrir comme image avec PIL
                    test_image = Image.open(io.BytesIO(file_content))
                    detected_format = test_image.format.lower() if test_image.format else "unknown"
                    file_type = f"image/{detected_format}"
                    logger.info(f"üìé D√©tection par contenu: {detected_format.upper()}")
                    test_image.close()
                except Exception as e:
                    logger.debug(f"Pas une image PIL: {e}")
            
            # 3. ACCEPTER TOUT TYPE COMMEN√áANT PAR image/
            if file_type and file_type.startswith("image/"):
                logger.info(f"‚úÖ Type image valid√©: {file_type}")
            
            logger.info(f"üîç Type original: {original_type} ‚Üí Type final: {file_type}")
            
            # === TRAITEMENT IMAGE (TOUS FORMATS) ===
            if file_type and file_type.startswith("image/"):
                try:
                    image = Image.open(io.BytesIO(file_content))
                    
                    # Convertir en RGB si n√©cessaire (pour PNG avec transparence, etc.)
                    if image.mode in ('RGBA', 'LA', 'P'):
                        background = Image.new('RGB', image.size, (255, 255, 255))
                        if image.mode == 'P':
                            image = image.convert('RGBA')
                        background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                        image = background
                        logger.info(f"üîÑ Image convertie de {image.mode} en RGB")
                    
                    # Analyser l'image avec SmolVLM + YOLO (si disponibles)
                    logger.info(f"üëÅÔ∏è [Analyse Image] Traitement de l'image: {filename} ({file_type})")
                    
                    # V√©rifier si les outils visuels sont disponibles
                    if ("vision" in self.agent.tools and self.agent.tools["vision"].is_ready) or ("detection" in self.agent.tools and self.agent.tools["detection"].is_ready):
                        # Sauvegarder temporairement l'image pour process_image
                        temp_path = Path(__file__).parent / "storage" / "temp" / filename
                        temp_path.parent.mkdir(parents=True, exist_ok=True)
                        image.save(temp_path)
                        
                        # UTILISER TOUS LES OUTILS: SmolVLM + YOLO + Mistral + Tavily
                        analysis = self.agent.process_image(
                            image_path=str(temp_path),
                            question=description or "Analyse cette image en d√©tail avec tous les objets visibles.",
                            detect_objects=True  # ‚úÖ TOUJOURS ACTIVER YOLO
                        )
                        
                        # Nettoyer le fichier temporaire
                        if temp_path.exists():
                            temp_path.unlink()
                        
                        # Extraire la description depuis le r√©sultat
                        # process_image retourne: {vision: {description: ...}, detection: ..., synthesis: ...}
                        if "error" in analysis:
                            logger.warning(f"‚ö†Ô∏è Erreur analyse IA: {analysis['error']}")
                            # Analyse basique sans IA
                            description_text = f"Image {file_type} de dimensions {image.width}x{image.height} pixels"
                            synthesis_text = f"Image charg√©e avec succ√®s. Mod√®les IA temporairement d√©sactiv√©s pour les tests."
                            analysis = {"tools_used": ["Mode Basique"]}
                        else:
                            vision_result = analysis.get("vision", {})
                            description_text = vision_result.get("description", "")
                            synthesis_text = analysis.get("synthesis", "")
                    else:
                        # Mode basique sans mod√®les IA
                        logger.info("üìù [Mode Basique] Analyse image sans IA")
                        description_text = f"Image {file_type} de dimensions {image.width}x{image.height} pixels"
                        synthesis_text = f"Image charg√©e avec succ√®s. Mod√®les IA temporairement d√©sactiv√©s pour permettre les tests de connectivit√©."
                        analysis = {"tools_used": ["Mode Basique"]}
                    
                    # Combiner vision et synth√®se pour FAISS
                    full_description = f"{description_text}\n\nSynth√®se: {synthesis_text}" if synthesis_text else description_text
                    
                    # Ajouter √† la m√©moire FAISS
                    doc_id = self.memory.add_document(
                        text=full_description,
                        metadata={
                            "filename": filename,
                            "type": "image",
                            "format": file_type,
                            "size": len(file_content),
                            "dimensions": f"{image.width}x{image.height}",
                            "vision": vision_result,
                            "synthesis": synthesis_text,
                            "analysis": analysis
                        },
                        doc_type="image"
                    )
                    
                    # AJOUTER LES R√âSULTATS AU FORMAT FLUTTER
                    results["documents"].append({
                        "id": doc_id,
                        "type": "image",
                        "format": file_type,
                        "dimensions": f"{image.width}x{image.height}",
                        "description": description_text,
                        "synthesis": synthesis_text,
                        "analysis": analysis
                    })
                    
                    # AJOUTER AUSSI DIRECTEMENT AU NIVEAU RACINE POUR FLUTTER
                    results["description"] = description_text
                    results["synthesis"] = synthesis_text
                    results["vision"] = vision_result
                    results["detection"] = analysis.get("detection")
                    results["tools_used"] = analysis.get("tools_used", [])
                    results["web_search"] = analysis.get("web_search")
                    
                    logger.info(f"‚úÖ Image analys√©e: {filename} ({image.width}x{image.height})")
                    image.close()
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur traitement image: {e}")
                    raise HTTPException(500, f"Erreur traitement image: {str(e)}")
            
            # === TRAITEMENT PDF AVEC CHUNKING INTELLIGENT POUR RAG ===
            elif file_type == "application/pdf":
                logger.info(f"üìÑ Traitement PDF RAG: {filename}")
                
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
                all_text = ""
                total_chunks = 0
                
                # √âTAPE 1: Extraire tout le texte
                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    if text.strip():
                        all_text += f"\n\n=== Page {page_num + 1} ===\n\n{text}"
                
                logger.info(f"üìñ PDF: {len(pdf_reader.pages)} pages, {len(all_text)} caract√®res")
                
                # √âTAPE 1.5: Si le PDF n'a pas de texte (PDF scann√©), extraire le texte des images
                is_scanned_pdf = len(all_text.strip()) < 100  # Moins de 100 caract√®res = probablement scann√©
                
                if is_scanned_pdf:
                    logger.info(f"üñºÔ∏è PDF scann√© d√©tect√© - Extraction du texte via analyse d'images...")
                    try:
                        pdf_document = fitz.open(stream=file_content, filetype="pdf")
                        
                        # Limiter √† 20 pages pour √©viter les traitements trop longs
                        max_pages = min(len(pdf_document), 20)
                        logger.info(f"üì∏ Analyse de {max_pages} pages (sur {len(pdf_document)})...")
                        
                        # Cr√©er un dossier temporaire pour les images
                        temp_dir = Path(__file__).parent / "storage" / "temp"
                        temp_dir.mkdir(parents=True, exist_ok=True)
                        
                        for page_num in range(max_pages):
                            page = pdf_document[page_num]
                            
                            # Convertir la page en image
                            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom pour meilleure qualit√©
                            
                            # Sauvegarder temporairement
                            temp_img_path = temp_dir / f"pdf_page_{page_num}.png"
                            pix.save(str(temp_img_path))
                            
                            # Analyser l'image avec SmolVLM
                            try:
                                if "vision" in self.agent.tools and self.agent.tools["vision"].is_ready:
                                    page_analysis = await self.agent.process_image(
                                        image_path=str(temp_img_path),
                                        query=f"Extrais et d√©cris tout le texte visible sur cette page {page_num + 1}. D√©cris aussi les sch√©mas, tableaux et √©l√©ments visuels importants.",
                                        detect_objects=False  # Pas besoin de YOLO pour du texte
                                    )
                                    
                                    page_text = page_analysis.get("vision", "")
                                    if page_text:
                                        all_text += f"\n\n=== Page {page_num + 1} (analys√©e visuellement) ===\n\n{page_text}"
                                else:
                                    # Mode basique
                                    logger.info(f"üìù [Mode Basique] Page {page_num + 1} - OCR non disponible")
                                    all_text += f"\n\n=== Page {page_num + 1} (PDF scann√© - OCR d√©sactiv√©) ===\n\n[Texte non extractible - mod√®les IA temporairement d√©sactiv√©s]"
                                
                                # Nettoyer l'image temporaire
                                if temp_img_path.exists():
                                    temp_img_path.unlink()
                                    
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è Erreur analyse page {page_num + 1}: {e}")
                                # Nettoyer m√™me en cas d'erreur
                                if temp_img_path.exists():
                                    temp_img_path.unlink()
                                continue
                        
                        pdf_document.close()
                        logger.info(f"‚úÖ Analyse visuelle compl√©t√©e: {len(all_text)} caract√®res extraits")
                        
                    except Exception as e:
                        logger.error(f"‚ùå Erreur extraction visuelle PDF: {e}")
                
                # √âTAPE 2: CHUNKING INTELLIGENT (d√©couper en morceaux optimaux)
                if len(all_text.strip()) > 0:
                    chunk_size = 1000  # ~1000 caract√®res par chunk
                    chunk_overlap = 200  # 200 caract√®res de chevauchement
                    
                    chunks = []
                    start = 0
                    while start < len(all_text):
                        end = start + chunk_size
                        
                        # Trouver la fin d'une phrase pour ne pas couper au milieu
                        if end < len(all_text):
                            # Chercher le dernier point, point d'exclamation ou point d'interrogation
                            last_period = max(
                                all_text.rfind('.', start, end),
                                all_text.rfind('!', start, end),
                                all_text.rfind('?', start, end),
                                all_text.rfind('\n', start, end)
                            )
                            if last_period != -1 and last_period > start + chunk_size // 2:
                                end = last_period + 1
                        
                        chunk = all_text[start:end].strip()
                        if chunk:
                            chunks.append(chunk)
                        
                        start = end - chunk_overlap  # Chevauchement pour garder le contexte
                    
                    logger.info(f"‚úÇÔ∏è PDF d√©coup√© en {len(chunks)} chunks intelligents")
                else:
                    logger.warning(f"‚ö†Ô∏è Aucun texte extrait du PDF - Cr√©ation d'un chunk de m√©tadonn√©es")
                    chunks = [f"Document PDF: {filename} - {len(pdf_reader.pages)} pages (PDF scann√© sans texte extractible)"]
                
                # √âTAPE 3: Ajouter chaque chunk √† FAISS
                for i, chunk in enumerate(chunks):
                    doc_id = self.memory.add_document(
                        text=chunk,
                        metadata={
                            "filename": filename,
                            "chunk_index": i,
                            "total_chunks": len(chunks),
                            "type": "pdf_chunk",
                            "chunk_size": len(chunk)
                        },
                        doc_type="pdf_rag"
                    )
                    
                    total_chunks += 1
                    
                    results["documents"].append({
                        "id": doc_id,
                        "type": "pdf_chunk",
                        "chunk_index": i,
                        "preview": chunk[:150] + "..."
                    })
                
                # √âTAPE 4: Extraire et analyser les images du PDF (SEULEMENT si ce n'est PAS un PDF scann√©)
                # Car si c'est scann√©, on a d√©j√† analys√© les pages compl√®tes ci-dessus
                if not is_scanned_pdf:
                    try:
                        pdf_document = fitz.open(stream=file_content, filetype="pdf")
                        
                        for page_num in range(min(len(pdf_document), 10)):  # Max 10 pages pour les images
                            page = pdf_document[page_num]
                            images = page.get_images()
                            
                            for img_index, img in enumerate(images[:3]):  # Max 3 images par page
                                try:
                                    xref = img[0]
                                    base_image = pdf_document.extract_image(xref)
                                    image_bytes = base_image["image"]
                                    
                                    # Analyser l'image
                                    if "vision" in self.agent.tools and self.agent.tools["vision"].is_ready:
                                        analysis = await self.agent.process_image(
                                            image_path=str(temp_img_path),
                                            query="D√©cris cette image extraite d'un document PDF.",
                                            detect_objects=False
                                        )
                                        
                                        vision_desc = analysis.get("vision", "")
                                    else:
                                        # Mode basique
                                        logger.info(f"üìù [Mode Basique] Image PDF {page_num + 1}.{img_index} - analyse d√©sactiv√©e")
                                        vision_desc = f"Image extraite de la page {page_num + 1} du PDF (analyse IA temporairement d√©sactiv√©e)"
                                    
                                    # Nettoyer
                                    if temp_img_path.exists():
                                        temp_img_path.unlink()
                                    
                                    # Ajouter √† FAISS seulement si on a une description
                                    if vision_desc:
                                        doc_id = self.memory.add_document(
                                            text=f"Image page {page_num + 1}: {vision_desc}",
                                            metadata={
                                                "filename": filename,
                                                "page": page_num + 1,
                                                "image_index": img_index,
                                                "type": "pdf_image"
                                            },
                                            doc_type="pdf_image"
                                        )
                                        
                                        results["documents"].append({
                                            "id": doc_id,
                                            "type": "pdf_image",
                                            "page": page_num + 1
                                        })
                                        
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è Erreur image PDF page {page_num}: {e}")
                                    continue
                        
                        pdf_document.close()
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Extraction images PDF √©chou√©e: {e}")
                
                results["total_pages"] = len(pdf_reader.pages)
                results["total_chunks"] = total_chunks
                results["description"] = f"PDF trait√©: {len(pdf_reader.pages)} pages, {total_chunks} chunks ajout√©s √† la base de connaissances"
                results["synthesis"] = f"‚úÖ Document '{filename}' ajout√© √† votre base de connaissances RAG avec {total_chunks} sections index√©es. Vous pouvez maintenant poser des questions sur ce document !"
                
                logger.info(f"‚úÖ PDF RAG trait√©: {total_chunks} chunks + images index√©s")
            
            else:
                raise HTTPException(400, f"Type de fichier non support√©: {file_type}")
            
            # Sauvegarder la m√©moire
            self.memory.save_to_disk(str(self.storage_path))
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement fichier: {e}")
            raise HTTPException(500, f"Erreur traitement: {str(e)}")
        
        return results
    
    def chat(
        self,
        message: str,
        conversation_id: str,
        use_memory: bool = True,
        temperature: float = 0.7
    ) -> ChatResponse:
        """
        üî• CHAT ULTRA-INTELLIGENT - UTILISE TOUS LES OUTILS DISPONIBLES
        
        Pipeline intelligent:
        1. D√©tection d'intention ‚Üí Type de r√©ponse n√©cessaire
        2. FAISS (M√©moire) ‚Üí Documents/images similaires du pass√©
        3. Tavily (Web) ‚Üí Recherche internet en temps r√©el si n√©cessaire
        4. SmolVLM + YOLO ‚Üí Analyse visuelle si contexte pertinent
        5. Mistral-7B (LLM) ‚Üí Synth√®se intelligente avec tous les outils
        """
        
        # ========================================
        # √âTAPE 1: D√âTECTION D'INTENTION
        # ========================================
        intent = self.detect_intent(message)
        system_prompt = self.get_prompt_by_intent(intent)
        
        logger.info(f"üéØ Intention d√©tect√©e: {intent}")
        
        tools_used = []  # Tracer les outils utilis√©s
        
        # ========================================
        # √âTAPE 2: RECHERCHE DANS LA M√âMOIRE FAISS
        # ========================================
        relevant_docs = []
        if use_memory:
            logger.info("üíæ [FAISS] Recherche dans la m√©moire vectorielle...")
            relevant_docs = self.memory.search(message, k=5)  # Augment√© √† 5 pour plus de contexte
            if relevant_docs:
                tools_used.append(f"FAISS ({len(relevant_docs)} docs)")
                logger.info(f"   ‚úì {len(relevant_docs)} documents pertinents trouv√©s")
        
        # ========================================
        # √âTAPE 3: ANALYSE DU BESOIN D'OUTILS VISUELS
        # ========================================
        message_lower = message.lower()
        needs_visual_search = any(keyword in message_lower for keyword in [
            "image", "photo", "voir", "montre", "visuel", "capture",
            "pr√©c√©dent", "dernier", "avant", "historique visuel"
        ])
        
        visual_context = None
        if needs_visual_search and relevant_docs:
            # Chercher des images dans les documents pertinents
            for doc in relevant_docs:
                if doc.get("type") == "image":
                    logger.info("üëÅÔ∏è [SmolVLM] Document visuel trouv√© dans FAISS")
                    visual_context = doc.get("metadata", {})
                    tools_used.append("SmolVLM (via FAISS)")
                    break
        
        # ========================================
        # √âTAPE 4: CONSTRUIRE CONTEXTE M√âMOIRE + STATISTIQUES
        # ========================================
        context = ""
        pdf_chunks_count = 0
        pdf_files = set()
        
        if relevant_docs:
            context = "\nüìö M√âMOIRE CONTEXTUELLE (FAISS):\n"
            for i, doc in enumerate(relevant_docs, 1):
                doc_type = doc.get('type', 'texte')
                doc_text = doc.get('text', '')[:150]
                context += f"{i}. [{doc_type}] {doc_text}...\n"
                
                # Compter les chunks PDF et les fichiers uniques
                if doc_type in ['pdf_rag', 'pdf_chunk']:
                    pdf_chunks_count += 1
                    metadata = doc.get('metadata', {})
                    filename = metadata.get('filename', '')
                    if filename:
                        pdf_files.add(filename)
        
        # ========================================
        # √âTAPE 5: HISTORIQUE CONVERSATIONNEL
        # ========================================
        history = self.memory.get_conversation(conversation_id)
        history_text = ""
        if history:
            logger.info(f"üìú Historique: {len(history[-2:])} derniers messages")
            for msg in history[-2:]:
                history_text += f"{msg.role}: {msg.content}\n"
        
        # ========================================
        # √âTAPE 6: RECHERCHE WEB TAVILY (Si n√©cessaire)
        # ========================================
        web_search_context = ""
        
        # Triggers de recherche web √©largis
        needs_web_search = (
            intent == "search" or
            any(keyword in message_lower for keyword in [
                "actualit√©", "news", "aujourd'hui", "r√©cent", "maintenant",
                "qui est", "c'est quoi", "qu'est-ce", "d√©finition",
                "recherche", "trouve", "cherche", "google",
                "derni√®re", "dernier", "nouveau", "nouvelle",
                "site web", "internet", "en ligne",
                # Ajouter des triggers pour logos/marques
                "logo", "marque", "entreprise", "soci√©t√©", "produit"
            ])
        )
        
        if needs_web_search and TAVILY_AVAILABLE and tavily_client:
            try:
                logger.info(f"üåê [Tavily] Recherche internet: '{message[:60]}...'")
                search_results = tavily_client.search(
                    query=message, 
                    max_results=3,
                    search_depth="basic"
                )
                
                if search_results.get("results"):
                    web_search_context = "\nüåê RECHERCHE INTERNET (Tavily):\n"
                    for i, result in enumerate(search_results.get("results", [])[:3], 1):
                        title = result.get('title', 'N/A')
                        content = result.get('content', '')[:200]
                        url = result.get('url', '')
                        web_search_context += f"{i}. {title}\n   {content}...\n   Source: {url}\n\n"
                    
                    tools_used.append(f"Tavily ({len(search_results.get('results', []))} r√©sultats)")
                    logger.info(f"   ‚úì {len(search_results.get('results', []))} r√©sultats trouv√©s")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Recherche Tavily √©chou√©e: {e}")
        
        # ========================================
        # √âTAPE 7: CONSTRUIRE PROMPT ENRICHI AVEC TOUS LES OUTILS
        # ========================================
        if intent == "explain_app":
            full_message = f"""{EXPLAIN_APP_PROMPT}

{context}
{web_search_context}

Question: {message}

R√©ponds en 3-4 phrases claires et pratiques."""
            max_tokens = 150
            temp = 0.3
            
        elif intent == "search" or web_search_context:
            full_message = f"""{SEARCH_PROMPT}

{web_search_context}
{context}

Question: {message}

R√©sume les informations trouv√©es en 3-5 phrases."""
            max_tokens = 200
            temp = 0.3
            
        elif intent in ["problem_solving", "summarization"]:
            prompt_map = {
                "problem_solving": PROBLEM_SOLVING_PROMPT,
                "summarization": SUMMARIZATION_PROMPT
            }
            full_message = f"""{prompt_map[intent]}

{context}
{web_search_context}

{message}"""
            max_tokens = 200
            temp = 0.5
            
        else:
            # Conversation normale avec TOUS les contextes disponibles
            full_message = f"""{SYSTEM_PROMPT}

{history_text}
{context}
{web_search_context}

Utilisateur: {message}

R√©ponds de mani√®re naturelle et concise."""
            max_tokens = 150
            temp = 0.7
        
        # ========================================
        # √âTAPE 8: G√âN√âRATION AVEC MISTRAL-7B (OU R√âPONSE PAR D√âFAUT)
        # ========================================
        if "llm" in self.tools and self.tools["llm"].is_ready:
            logger.info("üß† [Mistral-7B] G√©n√©ration de r√©ponse avec tous les contextes...")
            agent_result = self.agent.chat(
                message=full_message,
                with_voice=False,
                context={
                    "intent": intent,
                    "max_tokens": max_tokens,
                    "temperature": temp,
                    "tools_used": tools_used
                }
            )
            
            response_text = agent_result.get("response", "Aucune r√©ponse g√©n√©r√©e")
            tools_used.append("Mistral-7B (LLM)")
        else:
            # R√©ponse par d√©faut quand les mod√®les sont d√©sactiv√©s
            logger.info("üìù [Mode Basique] G√©n√©ration de r√©ponse simple (mod√®les d√©sactiv√©s)")
            if intent == "explain_app":
                response_text = "L'application CENTER est une plateforme de gestion d'employ√©s avec chat IA, reconnaissance faciale et tableau de bord. Elle permet de g√©rer les profils employ√©s, faire du pointage automatique et communiquer avec un assistant IA intelligent."
            elif intent == "search":
                response_text = "Fonction de recherche disponible. Les mod√®les IA sont temporairement d√©sactiv√©s pour permettre les tests de connectivit√©."
            else:
                response_text = f"Bonjour ! Je suis Kibali, votre assistant IA. Les mod√®les avanc√©s sont temporairement d√©sactiv√©s pour les tests, mais je peux vous aider avec des r√©ponses de base. Votre message : '{message}'"
            
            tools_used.append("Mode Basique (sans LLM)")
        
        # Ajouter les statistiques PDF si pr√©sentes
        if pdf_chunks_count > 0:
            pdf_stats = f"üìÑ RAG: {pdf_chunks_count} chunks"
            if len(pdf_files) > 0:
                pdf_stats += f" de {len(pdf_files)} PDF"
            tools_used.append(pdf_stats)
            logger.info(f"üìä Statistiques RAG: {pdf_chunks_count} chunks de {len(pdf_files)} PDFs")
        
        # ========================================
        # √âTAPE 9: M√âMORISATION
        # ========================================
        self.memory.add_to_conversation(
            conversation_id,
            ChatMessage(role="user", content=message, timestamp=datetime.now().isoformat())
        )
        self.memory.add_to_conversation(
            conversation_id,
            ChatMessage(role="assistant", content=response_text, timestamp=datetime.now().isoformat())
        )
        
        # R√©sum√© des outils utilis√©s
        tools_summary = " + ".join(tools_used)
        logger.info(f"‚úÖ R√©ponse g√©n√©r√©e - Outils: {tools_summary}")
        
        # Ajouter un footer avec les statistiques si des PDFs ont √©t√© utilis√©s
        if pdf_chunks_count > 0:
            response_footer = f"\n\n---\nüí° *R√©ponse bas√©e sur {pdf_chunks_count} section(s) de {len(pdf_files)} document(s) PDF*"
            response_text = response_text + response_footer
        
        return ChatResponse(
            response=response_text,
            conversation_id=conversation_id,
            sources=[{
                "id": doc["id"],
                "type": doc["type"],
                "similarity": doc["similarity"],
                "preview": doc["text"][:100],
                "tool": f"üìÑ RAG" if doc.get('type') in ['pdf_rag', 'pdf_chunk'] else "FAISS"
            } for doc in relevant_docs] if relevant_docs else None,
            reasoning=f"Outils utilis√©s: {tools_summary}",
            timestamp=datetime.now().isoformat()
        )

# ==========================================
# INSTANCE GLOBALE
# ==========================================

chat_manager = ChatAgentManager()

# ==========================================
# ROUTES API
# ==========================================

@app.get("/")
async def root():
    """Page d'accueil de l'API"""
    return {
        "name": "Chat Agent API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "upload": "/upload",
            "chat": "/chat",
            "history": "/conversation/{conv_id}",
            "search": "/search",
            "stats": "/stats"
        }
    }

@app.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    description: Optional[str] = Form(None)
):
    """
    Upload un fichier (image ou PDF) pour analyse
    
    Le fichier est analys√© et ajout√© √† la m√©moire vectorielle FAISS.
    """
    return JSONResponse(content={
        "filename": file.filename,
        "type": file.content_type,
        "description": "Upload temporairement d√©sactiv√© - mod√®les IA non charg√©s",
        "synthesis": "Fonctionnalit√© disponible une fois les mod√®les r√©activ√©s",
        "documents": []
    })

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Envoyer un message de chat
    
    L'agent utilise FAISS pour rechercher le contexte pertinent
    et g√©n√®re une r√©ponse intelligente.
    """
    # G√©n√©rer un ID de conversation si non fourni
    conv_id = request.conversation_id or f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # R√©ponse par d√©faut
    response_text = f"Bonjour ! Je suis Kibali, votre assistant IA. Les mod√®les avanc√©s sont temporairement d√©sactiv√©s pour les tests, mais je peux confirmer que votre message a √©t√© re√ßu : '{request.message}'"
    
    return ChatResponse(
        response=response_text,
        conversation_id=conv_id,
        sources=None,
        reasoning="Mode Basique (sans LLM)",
        timestamp=datetime.now().isoformat()
    )

@app.get("/conversation/{conv_id}")
async def get_conversation(conv_id: str):
    """R√©cup√©rer l'historique d'une conversation"""
    return {
        "conversation_id": conv_id,
        "messages": [],
        "total": 0,
        "note": "Historique temporairement d√©sactiv√© - mod√®les IA non charg√©s"
    }

@app.post("/search")
async def search_memory(query: str, k: int = 10):
    """Rechercher dans la m√©moire vectorielle"""
    return {
        "query": query,
        "results": [],
        "total": 0,
        "note": "Recherche temporairement d√©sactiv√©e - mod√®les IA non charg√©s"
    }

@app.get("/stats")
async def get_stats():
    """Statistiques de la m√©moire avec d√©tails RAG PDF"""
    return {
        "total_documents": 0,
        "total_vectors": 0,
        "conversations": 0,
        "embedding_dimension": 384,
        "rag_statistics": {
            "pdf_chunks": 0,
            "unique_pdfs": 0,
            "pdf_files": [],
            "images": 0,
            "other_documents": 0
        },
        "note": "Statistiques temporairement d√©sactiv√©es - mod√®les IA non charg√©s"
    }

@app.delete("/clear")
async def clear_memory():
    """Effacer toute la m√©moire"""
    return {"status": "memory cleared", "note": "M√©moire temporairement d√©sactiv√©e - mod√®les IA non charg√©s"}

@app.get("/pdf/{filename}")
async def get_pdf_details(filename: str):
    """Obtenir les d√©tails d'un PDF sp√©cifique"""
    return {
        "filename": filename,
        "total_chunks": 0,
        "total_characters": 0,
        "average_chunk_size": 0,
        "chunks": [],
        "note": "D√©tails PDF temporairement d√©sactiv√©s - mod√®les IA non charg√©s"
    }

# ==========================================
# LANCEMENT
# ==========================================

if __name__ == "__main__":
    local_ip = get_local_ip()
    port = 8001
    
    print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ü§ñ CHAT AGENT API - Multimodal avec FAISS          ‚ïë
‚ïë  Version 1.0.0                                        ‚ïë
‚ïë                                                       ‚ïë
‚ïë  üì° Serveur d√©marr√© sur:                             ‚ïë
‚ïë     - Local:   http://127.0.0.1:{port}                ‚ïë
‚ïë     - Network: http://{local_ip}:{port}              ‚ïë
‚ïë                                                       ‚ïë
‚ïë  üîó Endpoints disponibles:                           ‚ïë
‚ïë     - POST /chat       : Discussion avec l'agent    ‚ïë
‚ïë     - POST /upload     : Upload fichier             ‚ïë
‚ïë     - GET  /           : Page d'accueil             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚úÖ Copiez cette URL dans votre application Flutter:
   http://{local_ip}:{port}
    """)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=port,
        log_level="info"
    )
